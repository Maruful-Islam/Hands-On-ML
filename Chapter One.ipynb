{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 01- The Machine Learning Landscape\n",
    "\n",
    "In this chapter I have covered some of the most important concepts of machine learning. Like-\n",
    "    1. Machine Learning concepts and Why we use it.\n",
    "    2. Different types of ML-\n",
    "        * Supervised Learning\n",
    "        * Unsupervised Learning\n",
    "        * Semi-supervised Learning\n",
    "        * Reinforcement Learning  \n",
    "    3. Batch and Online Learning\n",
    "    4. Instance based and model Based learning\n",
    "    5. Main challenges of Machine Learning\n",
    "        * Bad Data-\n",
    "            > Insufficient quantity of training data\n",
    "            > Non representative training data\n",
    "            > Poor quality data\n",
    "        * Bad Algorithm\n",
    "            > Overfitting of the training data\n",
    "            > Underfitting the training data\n",
    "    6. Testing and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to plot some pretty figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore useless warnings \n",
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "datapath = os.path.join(\"datasets\", \"lifesat\", \"\")\n",
    "oecd_bli = pd.read_csv(datapath + \"oecd_bli_2015.csv\", thousands=',')\n",
    "gdp_per_capita = pd.read_csv(datapath + \"gdp_per_capita.csv\",thousands=',',delimiter='\\t',\n",
    "                             encoding='latin1', na_values=\"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function\n",
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    # it merges the GDP and Life satisfaction data into a single pandas data Frame\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "# Prepare the data\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X = np.c_[country_stats[\"GDP per capita\"]]\n",
    "y = np.c_[country_stats[\"Life satisfaction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "country_stats.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a linear model\n",
    "import sklearn.linear_model\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make a prediction for Cyprus\n",
    "X_new = [[22587]]  # Cyprus' GDP per capita\n",
    "print(model.predict(X_new)) # outputs [[ 5.96242338]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tring a k neighbors regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KNeighborsRegressor(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How would you define Machine Learning?\n",
    "    \n",
    "    Machine Learning is the science and art of computer programming so we can teach from Data rather than explicitly programmed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Can you name 4 types of problems where it shines?\n",
    "    \n",
    "    Machine learning gives us the opportunity to programmed without writing tons of rules. We can simply train machine with data. ML is great for-\n",
    "        * problems where we need a lot of hand tuning or long list of rules. like- spam filter\n",
    "        * complex problem where there is no traditional solution. like- image recognition\n",
    "        * fluctuate environments. Like- spam filter\n",
    "        * getting insights about complex problems and large amounts of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What is a labeled training set?\n",
    "    \n",
    "    Training dataset with desired output is called labeled training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.What are the two most common supervised task?\n",
    "    \n",
    "    The two most common supervised task are- Classification and Regression (Predict a target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Can you name 4 common unsupervised task?\n",
    "    \n",
    "    4 common unsupervised tasks are-\n",
    "        1. Clustering\n",
    "        2. Visualization\n",
    "        3. Dimensionality reduction\n",
    "        4. Association rule learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.What type of ML algorithm would you use to allow a robot to walk in various unknown terrains?\n",
    "    Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.What types of algorithm would you use to segment your customers into multiple groups?\n",
    "\n",
    "    If data is labeled then we can use classification algorithm (supervised learning), otherwise we can use clustering algorithm(unsupervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning algorithm?\n",
    "    \n",
    "    Spam detection problem is a supervised learning algorithm cause the training data set is labeled with spam or ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.What is an online learning system?\n",
    "    \n",
    "    In online learning, the system is trained incrementally feeding it data instances sequentially, either individually or by small groups called mini-batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.What is out of core learning?\n",
    "    \n",
    "    Online learning algorithms can also be used to train systems on huge datasets that cannot fit in one machine's main memory (RAM). This is called out-of-core learning. The algorithm loads part of data, runs a training step on that data, and repeats the process until it has run all of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.What type of learning algorithm relies on a similarity measure to make predictions?\n",
    "\n",
    "    Instance based learning algorithm relies on a similarity measure to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.What is the difference between a model parameter and a learning algorithm's hyperparameter?\n",
    "\n",
    "    Model Parameters are something that a model learns on its own. Model hyper-parameters are used to optimize the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?\n",
    "\n",
    "    Model based learning algorithm search for the optimal value of parameters in a model that will give the best results for the new instances. We often use a cost function or similar to determine what the parameter value has to be in order to minimize the function. The model makes prediction by using the value of the new instance and the parameters in its function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.Can you name four of the main challenges in Machine Learning?\n",
    "\n",
    "    * Insufficient quantity of training data\n",
    "    * Non-representative training data\n",
    "    * Poor quality data\n",
    "    * Irrelevant features\n",
    "    * Overfitting the training data\n",
    "    * Underfitting the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?\n",
    "\n",
    "    If the model performs poorly to new instances, then it has overfit on the training data. To solve this, we can do any of the following three: \n",
    "    * to gather more data.\n",
    "    * Fix data, removes outliers\n",
    "    * To simplify the model by selecting one with less parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.What is a test set and why would you want to use it?\n",
    "\n",
    "    A test set is used to estimate the generalization error that a model will make on new instances, before launching the model in production. The error rate on new cases is called the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.What is the purpose of a validation set?\n",
    "\n",
    "    A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.What can go wrong if you tune hyperparameters using the test set?\n",
    "\n",
    "    If I tune hyperparameters using the test set, I risk overfitting (less training loss but large validation error) the test set. The generalization error you measure will be optimistic (Launch model will perform worse than expectation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.What is cross-validation and why would you prefer it to a validation set?\n",
    "\n",
    "    Cross-validation is a technique that makes it possible to compare models (For model selection and hyperparameter tuning) without the need for a separate validation set. This saves precious training data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
